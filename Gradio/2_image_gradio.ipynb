{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshyadav1508/DeepLearningModel_POC/blob/main/Gradio/2_image_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URS-UPPSZ9P3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0mDdMwkNaQ3r"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import os,IPython\n",
        "import gradio as gr\n",
        "import io\n",
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZaVmEGlaTrU",
        "outputId": "24aa3c80-44b7-49df-eadc-bdcaa24622d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to ydshieh/vit-gpt2-coco-en and revision 65636df (https://huggingface.co/ydshieh/vit-gpt2-coco-en).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"image-to-text\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['generated_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "JYZ8jkI1ad60",
        "outputId": "336c3bd6-5f7b-4a44-bd45-089ef98405df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'a dog wearing a red hat and a red bow tie '}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
        "display(IPython.display.Image(url=image_url))\n",
        "get_completion(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yja8j8jTcB5T"
      },
      "outputs": [],
      "source": [
        "!wget \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\" -O \"christmas_dog.jpg\"\n",
        "\n",
        "!wget \"https://media.istockphoto.com/id/1284202626/photo/bird-image-from-katwijk-a-small-town-at-the-north-sea-coast-in-the-netherlands.jpg?s=2048x2048&w=is&k=20&c=LrPnd-BGU3msKyaTsB7_udcikKXo9vA2UYgIX5pHJXs=\" -O \"christmas_dog1.jpg\"\n",
        "\n",
        "!wget \"https://free-images.com/lg/e180/golden_gate_bridge_1654406.jpg\" -O \"gate.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "SUZfM2jEbFiz",
        "outputId": "ee90ec35-afca-47d1-e49a-874a1494b4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://11e5c94cf589fa16b3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://11e5c94cf589fa16b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://11e5c94cf589fa16b3.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# def image_to_base64_str(pil_image):\n",
        "#     byte_arr = io.BytesIO()\n",
        "#     pil_image.save(byte_arr, format='PNG')\n",
        "#     byte_arr = byte_arr.getvalue()\n",
        "#     return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    # base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(image)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"christmas_dog.jpg\", \"gate.jpg\", \"christmas_dog1.jpg\"])\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzFMJumteH9G",
        "outputId": "a3b52c55-3c01-43a5-d609-4b7d4f78d5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "gr.close_all()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrQwBiZjU3ahJBTOdN/0Ka",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}